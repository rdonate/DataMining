{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minería de Datos 2016/2017 - Rubén Donate Serrano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ggplot/utils.py:81: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access Timestamp as pandas.Timestamp\n",
      "  pd.tslib.Timestamp,\n",
      "/usr/local/lib/python2.7/dist-packages/ggplot/stats/smoothers.py:4: FutureWarning: The pandas.lib module is deprecated and will be removed in a future version. These are private functions and can be accessed from pandas._libs.lib instead\n",
      "  from pandas.lib import Timestamp\n",
      "/usr/local/lib/python2.7/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Antes de empezar es fundamental cargar las librerias de python!\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ggplot import *\n",
    "from scipy import stats, integrate\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "# Configuracion para seaborn\n",
    "%matplotlib inline\n",
    "mpl.rcParams[\"figure.figsize\"] = \"8, 4\"\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "# Imprimir un arbol\n",
    "\n",
    "import pydotplus \n",
    "from IPython.display import Image  \n",
    "\n",
    "def imprimeArbol(model, data, width):\n",
    "    fnames = data.columns.values[:-1]\n",
    "    lnames = data['label'].unique()\n",
    "    dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                             feature_names=fnames,  \n",
    "                             class_names=lnames,  \n",
    "                             filled=True, rounded=True,  \n",
    "                             special_characters=True)  \n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "    return Image(graph.create_png(), width=width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la importacion de todos los paquetes que van a ser necesarios para la resolucion de la practica y las funciones que se son han facilitado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesador de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def limpiaDataSet (df):\n",
    "    df_limpio = df.dropna(axis=0)\n",
    "    return df_limpio\n",
    "def separarAtributosClase(df,etiqueta):\n",
    "    df_limpio = limpiaDataSet(df)\n",
    "    atributos = df_limpio.drop(etiqueta, 1)\n",
    "    clase = df_limpio[etiqueta]\n",
    "    return atributos, clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto se procede a realizar un preprocesado de un DataSet generico, el cual se pasara mediante parametros a la funcion junto con el valor de la etiqueta que identifica a los valores de la clase, consistente en separar los atributos de los valores de la clase. Antes de esto, se realiza un limpieza generica, para lo cual se le procedera a pasarle como parametro del DataSet, del mismo eliminando los registros que poseen valores perdidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Envio informacion al servidor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pycurl, io, json\n",
    "\n",
    "semilla = 3955\n",
    "df_val = pd.read_csv(\"./data/titanic_validacion.csv\")\n",
    "df_val = df_val.drop(\"Name\", 1)\n",
    "df_val = df_val.drop(\"PassengerId\",1)\n",
    "df_train = pd.read_csv(\"./data/titanic_train.csv\")\n",
    "df_train = df_train.drop(\"Name\", 1)\n",
    "df_train = df_train.drop(\"PassengerId\",1)\n",
    "atrib_train , clase_train = separarAtributosClase(df_train,\"label\")\n",
    "\n",
    "def envioPrediccion(prediccion):\n",
    "    user       = 'Ruben.Donate@alu.uclm.es'\n",
    "    passwd     = 'TNRQB7ZO'\n",
    "    # Este código recibe directamente el vector de predicciones y lo convierte a una\n",
    "    # String separando los valores por comas\n",
    "    pred_str   = ','.join(prediccion.tolist())\n",
    " \n",
    "    url  = \"http://212.47.226.96/predict\"\n",
    "    data = json.dumps({'user':user, 'passwd':passwd, 'prediction':pred_str})\n",
    "    \n",
    "    out = io.BytesIO()\n",
    "    c = pycurl.Curl()\n",
    "    c.setopt(c.URL, url)\n",
    "    c.setopt(pycurl.HTTPHEADER, ['Content-Type: application/json'])\n",
    "    c.setopt(pycurl.POST, 1)\n",
    "    c.setopt(c.POSTFIELDS, data)\n",
    "    c.setopt(c.WRITEFUNCTION, out.write)\n",
    "    \n",
    "    c.perform()\n",
    "    \n",
    "    response = json.loads(out.getvalue().decode())\n",
    "    print(\"Response: \",response)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto, se realiza las importaciones y la funcion personalizada en mi caso para el envio de la predicion al servidor para su validacion. En esta personalizacion realizado una limpieza de los valores perdidos de los valores necesarios para realizar el entrenamiento. A continuación, se separan los atributos predictores de los valores de la clase para proceder a entrenar el modelo y a partir de este punto realizar la prediccion. Esta prediccion se procede a su envio con el usuario y la contraseña que se me ha facilitado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vecinos={}\n",
    "arboles={}\n",
    "\n",
    "modeloMejorVecino=()\n",
    "\n",
    "modeloMejorArbol=()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tener almacenada toda la información que se ha generado he decidido utilizar un diccionario y una variable con el mejor valor para cada uno de los modelos que se ha tenido que implementar en el algoritmo. Esto lo he realiza de este modo para que sea posible mostar los resultados obtenidos en cada uno de los modelos generados. Por ese motivo en cualquiera de los casos un elemento sería una tupla con una identificación del modelo, en el knn sería el valor de k y para los arboles una tupla con los parametros que se ha utilizado para su configuracion, y otro elemento que es otraa tupla con el modelo generado, los valores obtenidos a traves del cross validation y la media del mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def printTable(list):\n",
    "    table = \"\"\"<table>%s</table>\"\"\"\n",
    "    row = \"\"\"<tr>%s</tr>\"\"\"\n",
    "    cell = \"\"\"<td>%s</td>\"\"\"\n",
    "    report =  table % ''.join([row % (cell % x[0] + cell % x[1]) for x in list])\n",
    "    display(HTML(report))\n",
    "\n",
    "def printTable2(list):\n",
    "    table = \"\"\"<table>%s</table>\"\"\"\n",
    "    row = \"\"\"<tr>%s</tr>\"\"\"\n",
    "    cell = \"\"\"<td>%s</td>\"\"\"\n",
    "    report =  table % ''.join([row % (cell % x[0] + cell % x[1] + cell % x[2] + cell % x[3] + cell % x[4]) for x in list])\n",
    "    display(HTML(report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de los Dataset de Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto, se genera una lista de DataSet a los cuales se le realizara una eliminacion de los valores que no tiene significado para la clasificacion que se pueden observar a simple vista, por ejemplo los identificadores o los nombre que identifican a un elemento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base de Datos Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irisdf = pd.read_csv(\"./data/iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base de Datos Pima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pimadf = pd.read_csv(\"./data/pima.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base de Datos Wisconsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wisconsindf = pd.read_csv(\"./data/wisconsin.csv\")\n",
    "wisconsindf = wisconsindf.drop(\"patientId\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base de Datos de Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanicdf = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un principio, tenia pensado realizar las pruebas con cada uno de los DataSet. Pero al final, solo trabaje con este DataSet, el cual se recupera del proceso de envio una vez limpiado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossValidation(modelo,df,etiqueta,partes,medida,semilla):\n",
    "    np.random.seed(seed=semilla)\n",
    "    atributos, clase = separarAtributosClase(df,etiqueta)\n",
    "    scores = cross_val_score(modelo, atributos, clase, cv=partes, scoring=medida)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo que realizamos es declarar una funcion al cual se encargara de realizar la validacion cruzada y devolvera los valores que se han obtenido para ese caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos por defecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion, procedere a crear las funciones para generar los modelos con los parametros de manera generica, las cuales devolverán la tupla con el modelo, los valores obtenidos en la validacion cruzada y la media de estos valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelokNN (k,df,etiqueta,partes,medida,seed):\n",
    "    modelo = neighbors.KNeighborsClassifier(k)\n",
    "    metrica = crossValidation(modelo,df,etiqueta,partes,medida,seed)\n",
    "    return (modelo,metrica,metrica.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el knn lo que se ha realizado es paraserle a la funcion todos los valores necesarios para generar el modelo, en este caso el valor de la k, y para realizar la validacion cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arbol de Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modeloArbol (df,etiqueta,criterio,profundidad,minEjemplos,poda,partes,medida,seed):\n",
    "    modelo= tree.DecisionTreeClassifier(criterion = criterio, max_depth = profundidad, min_samples_split = minEjemplos, min_impurity_split = poda, random_state = seed)\n",
    "    metrica = crossValidation(modelo,df,etiqueta,partes,medida,seed)\n",
    "    return (modelo,metrica,metrica.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del mismo modo que en el caso del knn, lo que se ha realizado es pasar a la funcion arbol todos los parametros necesarios para configurar el arbol, los cuales son criterio que establece la medida a partir de la cual se generara el arbol, profundidad que podra alcanzar el arbol, numero minimo de ejemplos que minimo de instancias a partir del cual no ramifica, poda que es el valor a partir de la ganancia de informacion del nodo, el numero aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selector de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 3568\n",
    "k = 2\n",
    "etiqueta = \"label\"\n",
    "medida = \"accuracy\"\n",
    "partes = 10\n",
    "df = titanicdf\n",
    "knnPrevio = modelokNN ((k-1),df,etiqueta,partes,medida,seed)\n",
    "vecinos[(k-1)]=knnPrevio\n",
    "modeloMejorVecino = knnPrevio\n",
    "knn = modelokNN (k,df,etiqueta,partes,medida,seed)\n",
    "vecinos[k]=knn\n",
    "while (abs(knnPrevio[2]-knn[2]))>0.0001:\n",
    "    if (knn[2]>modeloMejorVecino[2]):\n",
    "        modeloMejorVecino = knn\n",
    "    knnPrevio = knn\n",
    "    k+=1\n",
    "    knn = modelokNN (k,df,etiqueta,partes,medida,seed)\n",
    "    vecinos[k]=knn\n",
    "if (knn[2]>modeloMejorVecino[2]):\n",
    "    modeloMejorVecino = knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo implementado consiste realizar un bucle si el valor absoluto de media del modelo para k-1 menos el de k es mayor de 0.0001 eso quiere decir que el modelo de k respecto del anterior empeora o mejora un poco por lo cual se de para y se selecciona el valor mejor que se ha obtenido hasta el momento. El valor de k en cada iteraccion del bucle se incrementa en uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 3568\n",
    "etiqueta = \"label\"\n",
    "medida = \"accuracy\"\n",
    "partes = 10\n",
    "df = titanicdf\n",
    "criterio = (\"entropy\",\"gini\")\n",
    "profundidad = None\n",
    "minEjemplos = 2\n",
    "poda = 1e-7\n",
    "modeloMejorArbol = modeloArbol (df,etiqueta,criterio[0],profundidad,minEjemplos,poda,partes,medida,seed)\n",
    "clasificador = modeloMejorArbol[0].fit(atrib_train , clase_train)\n",
    "min_profundidad = 1\n",
    "max_profundidad = clasificador.tree_.max_depth\n",
    "arboles[(criterio[0],max_profundidad,minEjemplos,poda)]=modeloMejorArbol\n",
    "profundidad =int((max_profundidad-min_profundidad)/2)\n",
    "arbol=modeloArbol(df,etiqueta,criterio[0],profundidad,minEjemplos,poda,partes,medida,seed)\n",
    "arboles[(criterio[0],profundidad,minEjemplos,poda)]=arbol\n",
    "while ((modeloMejorArbol[2]<arbol[2])and(max_profundidad-min_profundidad>=1)):\n",
    "    modeloMejorArbol=arbol\n",
    "    max_profundidad=profundidad\n",
    "    profundidad =int((max_profundidad-min_profundidad)/2)\n",
    "    for c in criterio:\n",
    "        aux_arbol1=modeloArbol(df,etiqueta,c,profundidad,minEjemplos,poda,partes,medida,seed)\n",
    "        arboles[(c,profundidad,minEjemplos,poda)]=aux_arbol1\n",
    "        if aux_arbol1[2]>=arbol[2]:\n",
    "            arbol=aux_arbol1\n",
    "    if ((modeloMejorArbol[2]>=arbol[2])and(max_profundidad-profundidad>=0)):\n",
    "        min_profundidad = profundidad\n",
    "        profundidad =int((max_profundidad-min_profundidad)/2)\n",
    "        for c in criterio:\n",
    "            aux_arbol2=modeloArbol(df,etiqueta,c,profundidad,minEjemplos,poda,partes,medida,seed)\n",
    "            arboles[(c,profundidad,minEjemplos,poda)]=aux_arbol2\n",
    "            if aux_arbol2[2]>=arbol[2]:\n",
    "                arbol=aux_arbol2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo de selección de atributos lo he centrado en obtener la profundidad optima y para los dos criterios de evaluación. Para realizarlo se ha entrenado un arbol con los valores por defecto para obtener una profundidad de partida que se considerara como maxima. Con este valor y un minimo de uno se ha implementado un algoritmo de bisiceccion para obtener el valor de la manera mas eficaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (modeloMejorVecino[2]>modeloMejorArbol[2]):\n",
    "    clasificador = modeloMejorVecino[0].fit(atrib_train , clase_train)\n",
    "else:\n",
    "    clasificador = modeloMejorArbol[0].fit(atrib_train , clase_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediccion = clasificador.predict(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Número Vecinos</td><td>Accuracy</td></tr><tr><td>1</td><td>0.647558790594</td></tr><tr><td>2</td><td>0.646539753639</td></tr><tr><td>3</td><td>0.663393057111</td></tr><tr><td>4</td><td>0.666550951848</td></tr><tr><td>5</td><td>0.655968645017</td></tr><tr><td>6</td><td>0.669832026876</td></tr><tr><td>7</td><td>0.659227323628</td></tr><tr><td>8</td><td>0.662463605823</td></tr><tr><td>9</td><td>0.66241881299</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "listaAccuracyVecinos=[(\"Número Vecinos\", \"Accuracy\")]\n",
    "for vecino in vecinos:\n",
    "    listaAccuracyVecinos.append((vecino,vecinos[vecino][2]))\n",
    "printTable(listaAccuracyVecinos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Criterio</td><td>Profundidad</td><td>Minimo Ejemplos</td><td>Poda</td><td>Accuracy</td></tr><tr><td>gini</td><td>5</td><td>2</td><td>1e-07</td><td>0.79477043673</td></tr><tr><td>entropy</td><td>23</td><td>2</td><td>1e-07</td><td>0.754423292273</td></tr><tr><td>entropy</td><td>2</td><td>2</td><td>1e-07</td><td>0.786203807391</td></tr><tr><td>entropy</td><td>11</td><td>2</td><td>1e-07</td><td>0.777737961926</td></tr><tr><td>entropy</td><td>1</td><td>2</td><td>1e-07</td><td>0.784132138858</td></tr><tr><td>entropy</td><td>5</td><td>2</td><td>1e-07</td><td>0.803146696529</td></tr><tr><td>gini</td><td>1</td><td>2</td><td>1e-07</td><td>0.784132138858</td></tr><tr><td>gini</td><td>2</td><td>2</td><td>1e-07</td><td>0.785139977604</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "listaAccuracyArboles=[(\"Criterio\",\"Profundidad\",\"Minimo Ejemplos\",\"Poda\", \"Accuracy\"),]\n",
    "for tree in arboles:\n",
    "    listaAccuracyArboles.append((tree[0],tree[1],tree[2],tree[3],arboles[tree][2]))\n",
    "printTable2(listaAccuracyArboles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#envioPrediccion(prediccion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
