{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 3 - Ensembles y selección de variables Minería de Datos 2016/2017 - Rubén Donate Serrano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica tendremos dos objetivos principales:\n",
    "\n",
    "### A) Uso y ajuste de métodos basados en ensembles\n",
    "Al igual que en la práctica anterior se busca que el alumno aprenda a utilizar los 4 modelos de ensemble vistos y a compararlos con el algoritmo base (especialmente árboles de decisión), para ello se plantean los siguientes ejercicios:\n",
    "\n",
    "* **A.1) Implementación básica de un ensemble de manera manual:**\n",
    "    ```\n",
    "        Pseudocodigo:\n",
    "        Generar una lista de datos muestreados (con/sin remplazo, con/sin muestreo de atributos)\n",
    "        Aprender un clasificador para cada muestra\n",
    "        Obtener predicciones para cada modelo\n",
    "        Obtener la moda de dichas predicciones\n",
    "    ```\n",
    "    \n",
    "*  **A.2) Uso de Bagging, Boosting, Random Forest y Gradient Boosting**: Aprender y ajustar los parámetros de los distintos modelos para maximizar la clasificación. Comparar estos resultados con el ensemble implementado manualmente.\n",
    "  \n",
    "### B) Selección de variables\n",
    "\n",
    "Al igual que en el caso anterior, se busca que el alumno intente **mejorar** los resultados obenidos utilizando clasificadores base o ensembles al aplicar técnicas de selección de variables.\n",
    "\n",
    "* **B.1 Utilizar un método filter basado en rankings para evaluar distintos subconjuntos**\n",
    "* **B.2 Implementar al menos un algoritmo de búsqueda wrapper**\n",
    "* **B.3 (Opcional) Implementar CFS**\n",
    "\n",
    "\n",
    "### Consejos\n",
    "\n",
    "En esta tarea se valorará muy positivamente que se realice de manera correcta el aprendizaje y la evaluación identificando distintos conjuntos de entrenamiento y test así como usando validación cruzada. Los resultados se contrastarán para los datos pima, wisconsin y titanic, siendo obligatorio **realizar al menos una subida al servidor de los resultados obtenidos para titanic**.\n",
    "\n",
    "Se valorará muy positivamente también el uso de tablas y gráficas para exponer los resultados.\n",
    "\n",
    "En el caso de la selección de variables se valorará también exponer claramente comparativas entre las distintas métricas obtenidas por los atributos para corroborar si existen diferencias entre métodos wrapper y filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso y ajuste de métodos basados en ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso lo que se realizara es adaptar el selector de las variables que se ha implementados en la práctica 2 a los nuevos modelos que vamos a ver para después realizar el análisis de los atributos y su selección comparando los resultados con los obtenidos en las primeras selecciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que vamos a realizar, igual que en la práctica 2, es importar los modulos necesarios para realizar esta práctica y las configuraciones necesarias para los mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ggplot/utils.py:81: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access Timestamp as pandas.Timestamp\n",
      "  pd.tslib.Timestamp,\n",
      "/usr/local/lib/python2.7/dist-packages/ggplot/stats/smoothers.py:4: FutureWarning: The pandas.lib module is deprecated and will be removed in a future version. These are private functions and can be accessed from pandas._libs.lib instead\n",
      "  from pandas.lib import Timestamp\n",
      "/usr/local/lib/python2.7/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# Antes de empezar es fundamental cargar las librerias de python!\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ggplot import *\n",
    "from scipy import stats, integrate\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "# Configuracion para seaborn\n",
    "%matplotlib inline\n",
    "mpl.rcParams[\"figure.figsize\"] = \"8, 4\"\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También, se ha creado una función, que se llama envioPrediccion, utilizada para enviar los resultados al servidor de minikaggle que se nos ha proporcionado para esta práctica en el anexo (AnexoMiniKaggle). En esta, se realiza las importaciones, la carga y el tratamiento de los DataSet por defecto proporcionado en el mismo anexo y la funcion que realiza el envio de la predicion al servidor para su validación, la cual se le ha pasado por parametro a la misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pycurl, io, json\n",
    "\n",
    "semilla = 3955\n",
    "df_val = pd.read_csv(\"./data/titanic_validacion.csv\")\n",
    "df_val = df_val.drop(\"Name\", 1)\n",
    "df_val = df_val.drop(\"PassengerId\",1)\n",
    "df_train = pd.read_csv(\"./data/titanic_train.csv\")\n",
    "df_train = df_train.drop(\"Name\", 1)\n",
    "df_train = df_train.drop(\"PassengerId\",1)\n",
    "atrib_train = df_train.drop('label', 1)\n",
    "clase_train = df_train['label']\n",
    "\n",
    "\n",
    "def envioPrediccion(prediccion):\n",
    "    user       = 'Ruben.Donate@alu.uclm.es'\n",
    "    passwd     = 'TNRQB7ZO'\n",
    "    # Este código recibe directamente el vector de predicciones y lo convierte a una\n",
    "    # String separando los valores por comas\n",
    "    pred_str   = ','.join(prediccion)\n",
    " \n",
    "    url  = \"http://212.47.226.96/predict\"\n",
    "    data = json.dumps({'user':user, 'passwd':passwd, 'prediction':pred_str})\n",
    "    \n",
    "    out = io.BytesIO()\n",
    "    c = pycurl.Curl()\n",
    "    c.setopt(c.URL, url)\n",
    "    c.setopt(pycurl.HTTPHEADER, ['Content-Type: application/json'])\n",
    "    c.setopt(pycurl.POST, 1)\n",
    "    c.setopt(c.POSTFIELDS, data)\n",
    "    c.setopt(c.WRITEFUNCTION, out.write)\n",
    "    \n",
    "    c.perform()\n",
    "    \n",
    "    response = json.loads(out.getvalue().decode())\n",
    "    print(\"Response: \",response)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimo, se ha creado una función para la visualización de los resultados en formato HTML en forma de tabla para que sea mas comoda su visualización. Esta función se ha creado tomando como base la que se proporciono en la práctica 3 pero con la peculiaridad que se ha generalizado para poder mostar listas que contengan los elementos que sean necesarios de manera automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def printTable(list):\n",
    "    table = \"\"\"<table>%s</table>\"\"\"\n",
    "    row = \"\"\"<tr>%s</tr>\"\"\"\n",
    "    cell = \"\"\"<td>%s</td>\"\"\"\n",
    "    report =  table % ''.join([row % ''.join([(cell % xi) for xi in x]) for x in list])\n",
    "    display(HTML(report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A continuación, se empezará a ver las implementaciones que he realizado para el método de selección que he diseñado. Siendo el primero punto que se explicara el proceso de pretratamiento que se le realiza a los a clasificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesador de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este paso es el mas importante en un proceso de Minería de Datos. Esto es debido a que según el pretratamiento de los datos se pueden obtener resultados distintos. El problema es que se tiene realizar el pretratamiento de los datos de manera generica para que pueda utilizarse con cualquier DataSet que se nos proporcione. Esto hace que solo se pueda tratar los valores pedidos que pueda tener el DataSet, ya que como se va a trabajar con árboles no es necesario la normalización de los valores de los mismos, conforme se ha podido comprobar en la práctica 2. Esto hace que la función limpiaDataSet unicamente rellene los valores perdidos que pueda tener el DataSet con el valor de la mediana obtenido para ese atributo y ese DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def limpiaDataSet (df):\n",
    "    df_limpio = df.fillna(df.median())\n",
    "    return df_limpio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También, se ha creado una función que se encarga de devolver los atributos y la clase, la cual se identifica mediante una la etiqueta que es pasada por paramentro, separados de un DataSet que también es pasado por parametro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separarAtributosClase(df,etiqueta):\n",
    "    dfLimpio = limpiaDataSet(df)\n",
    "    atributos = dfLimpio.drop(etiqueta, 1)\n",
    "    clase = dfLimpio[etiqueta]\n",
    "    return atributos, clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto, los siguiente que nos nos toca es carga los datos con los que vamos a trabajar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de los Dataset de Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto, cargaremos los DataSet con los que será posible operar para su clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base de Datos Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irisdf = pd.read_csv(\"./data/iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base de Datos Pima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pimadf = pd.read_csv(\"./data/pima.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base de Datos Wisconsin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este DataSet, además de cargar el DataSet se ha procedido a eliminar un atributo que no aportaba información como es el Id del paciente, al ser distinto para cada paciente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wisconsindf = pd.read_csv(\"./data/wisconsin.csv\")\n",
    "wisconsindf = wisconsindf.drop(\"patientId\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base de Datos de Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un principio, se establece que los DataSets para trabajar eran **iris, pima y wisconsin**. Pero posteriormente se nos proporciono el DataSet Titanic. Este último, es a partir del cual se va a evaluar la predicción y el modelo, mediante un conjunto de valores no proporcionados para entrerar el modelo. Por ese motivo, se ha escogido realizar todo el estudio sobre este DataSet, aunque la implementación al ser generica es completamente funcional con cualquiera de los otros DataSet proporcionado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanicdf = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se nos pedía que en los experimentos utilizaramos validación cruzada para obtener los resultados, por ese motivo he creado una función en la que se le pasa como parametro un modelo, un DataSet, la etiqueta que identifica a la clase, las partes en las que se va a dividir el DataSet, la metrica que se desea que nos devuelva, y una semilla. Todo esto para que la función poceda a devolvernos el array que ha obtenido de aplicar la validación cruzada con los parametros que se le han pasado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossValidation(modelo, atributos, clase, partes, medida, semilla):\n",
    "    np.random.seed(seed=semilla)\n",
    "    scores = cross_val_score(modelo, atributos, clase, cv=partes, scoring=medida)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto ya hemos terminado, con los tareas comunes y comenzaré con la implementación de mi ensembler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembler Propio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ensembler es un módelo que construye otros modelos diferentes para posteriormente agregar los resultados obtenido, para así intentar reducir la varianza e intentar mejor los resultados.\n",
    "\n",
    "Para mi implementación del Ensembler, he creado una función que realiza un muestreo del DataSet con el que trabajamos y otra que es el propio ensembler, las cuales explicare a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Muestreo con Reemplazo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función se ha creado para generar una muestra del DataSet que se el pasa por parametro con el tamaño que también se le pasa por parametro y una semilla. También se le pasa por parametro si en el muestro se le permite o no realizar reemplazo cuando se selecciona una ocurrencia del DataSet. He decidido realizarlo así para poder tenerlo controlado lo maximo posible para a continuación poder usarlo comodamente en mi ensembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seleccionMuestra(df,tamano,reemplazo,semilla):\n",
    "    np.random.seed(semilla)\n",
    "    elegido = df.sample(n=tamano,random_state=semilla,replace=reemplazo)\n",
    "    return elegido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensembler Propio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mi ensembler, he decido utilizar los árboles de decisión vistos en la práctica 2 como modelo para este. Por ello lo que se realizar es limpiar el DataSet, fijar el valor de la semilla para obtener número aleatorios, se inicializan resultadosPedicion donde se almacena la predicción las los elementos a clasificar, muestas donde se almacena la muestras utilizadas para construir cada uno de los modelo, predicciones donde se almacena la predicción que realiza cada uno de los modelos que se construyen y resultadoEnsembler donde se almacena la información que hemos generado durante todo el proceso, como puede ser la muestra utilizada, el arbol construido, la predicción realizada y los resultados que obtiene dicho arbol. A continuación, lo que se realiza es selecionar una semilla para le modelo, obtener una muestra del DataSet original. A partir de esta muestra se construyele el árbol de decisión, se entrena con los datos de la muestra generada y por ultimo se genera la predicción para los datos que deseamos clasificar. Esto es repetido tantas veces como modelos deseamos que nos genere. Para terminar, realizar una agregación de los resutlados obtenidos en cada uno de los módelos utilizando la técnica del voto por la mayoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modeloEnsebler(df,tamanoMuestra,reemplazo,test,numModelos,criterio,profundidad,minEjemplos,poda,etiqueta,partes,medida,seed):\n",
    "    df = limpiaDataSet(df)\n",
    "    np.random.seed(seed)\n",
    "    resultadoPrediccion=[0 for i in range(len(test))]\n",
    "    muestras=[]\n",
    "    predicciones=[[0 for j in range(numModelos)] for i in range(len(test))]\n",
    "    metricas=[]\n",
    "    resultadoEnsembler=[]\n",
    "    for i in range (numModelos):\n",
    "        seedModel=int(10000*np.random.random())\n",
    "        muestra = seleccionMuestra(df,tamanoMuestra,reemplazo,seedModel)\n",
    "        muestras.append(muestra)\n",
    "        arbolParaEnsembler = modeloArbol(muestra,etiqueta,criterio,profundidad,minEjemplos,poda,partes,medida,seedModel)\n",
    "        atributos, clase = separarAtributosClase(muestra,etiqueta)\n",
    "        metricas.append(arbolParaEnsembler[2])\n",
    "        clasificador = arbolParaEnsembler[0].fit(atributos,clase)\n",
    "        prediccion = clasificador.predict(test)\n",
    "        resultadoEnsembler.append((muestra,arbolParaEnsembler[0],prediccion,arbolParaEnsembler[1],arbolParaEnsembler[2]))\n",
    "        for k in range(len(prediccion)):\n",
    "            predicciones[k][i]=prediccion[k]\n",
    "    for j in range(len(predicciones)):\n",
    "        resultadoPrediccion[j]=mode(predicciones[j]).mode[0]\n",
    "    return (resultadoEnsembler,resultadoPrediccion,metricas,np.mean(metricas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, como en mi algoritmo de selección para automatizarlo en un bucle he creado una función de orden superior que me devuelva la función de este modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modeloEnseblerSup():\n",
    "    return modeloEnsebler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos Genericos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación creare el resto de los módelos genericos de ensembler que hemos estudiado. Todos estos módelos también han sido creado utilizando el orden superior para su posterior tratamiento en el proceso de seleccion de los módelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bargging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estrategia básica tras el algoritmo de **bagging** es la agregación de distintos clasificadores que han sido aprendidos mediante técnicas de muestreo con remplazo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modeloBaggingSup(modeloBase):\n",
    "    def modeloBagging(df,tamanoMuestra,reemplazo,test,numModelos,criterio,profundidad,minEjemplos,poda,etiqueta,partes,medida,seed):\n",
    "        df = limpiaDataSet(df)\n",
    "        resultadoEnsembler = BaggingClassifier(modeloBase(criterio,profundidad,minEjemplos,poda,seed),n_estimators=numModelos,max_samples=(tamanoMuestra/len(df)),bootstrap=reemplazo,random_state=seed)\n",
    "        atributos, clase = separarAtributosClase(df,etiqueta)\n",
    "        metrica = crossValidation(resultadoEnsembler,atributos,clase,partes,medida,seed)\n",
    "        clasificador = resultadoEnsembler.fit(atributos,clase)\n",
    "        resultadoPrediccion = clasificador.predict(test)\n",
    "        return (resultadoEnsembler,resultadoPrediccion,metrica,metrica.mean())\n",
    "    return modeloBagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estrategia de boosting es completamente diferente a la anterior, ya que en lugar de reducir la varianza al aprender múltiples clasificadores independientes, realiza un proceso iterativo en el que sobreajustaremos los datos en aquellas instancias más complicadas de aprender para nuestro modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modeloBoostingSup(modeloBase):\n",
    "    def modeloBoosting(df,tamanoMuestra,reemplazo,test,numModelos,criterio,profundidad,minEjemplos,poda,etiqueta,partes,medida,seed):\n",
    "        df = limpiaDataSet(df)\n",
    "        resultadoEnsembler = AdaBoostClassifier(modeloBase(criterio,profundidad,minEjemplos,poda,seed),n_estimators=numModelos,random_state=seed)\n",
    "        atributos, clase = separarAtributosClase(df,etiqueta)\n",
    "        metrica = crossValidation(resultadoEnsembler,atributos, clase,partes,medida,seed)\n",
    "        clasificador = resultadoEnsembler.fit(atributos,clase)\n",
    "        resultadoPrediccion = clasificador.predict(test)\n",
    "        return (resultadoEnsembler,resultadoPrediccion,metrica,metrica.mean())\n",
    "    return modeloBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una alternativa muy popular al bagging es el clasificador random forest. En este caso también se utiliza muestreo con remplazo, pero adicionalmente integra otras técnicas de regularización en el aprendizaje de los árboles de decisión para ampliar la generalización del ensemble.\n",
    "\n",
    "Un clasificador random forest siempre utiliza árboles de decisión como submodelos y por ello no requiere un clasificador base para su definición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modeloRandomForrestSup():\n",
    "    def modeloRandomForrest(df,tamanoMuestra,reemplazo,test,numModelos,criterio,profundidad,minEjemplos,poda,etiqueta,partes,medida,seed):\n",
    "        df = limpiaDataSet(df)\n",
    "        resultadoEnsembler = RandomForestClassifier(n_estimators=numModelos,criterion=criterio,max_depth=profundidad,min_samples_split=minEjemplos,min_impurity_split = poda,bootstrap=reemplazo,n_jobs=numModelos,random_state=seed)\n",
    "        atributos, clase = separarAtributosClase(df,etiqueta)\n",
    "        metrica = crossValidation(resultadoEnsembler,atributos, clase,partes,medida,seed)\n",
    "        clasificador = resultadoEnsembler.fit(atributos,clase)\n",
    "        resultadoPrediccion = clasificador.predict(test)\n",
    "        return (resultadoEnsembler,resultadoPrediccion,metrica,metrica.mean())\n",
    "    return modeloRandomForrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es una generalización del algoritmo de boosting que utiliza funciones de coste concretas en referencia al proceso de aprendizaje de árboles. Actualmente es una de las técnicas más exitosas para resolver problemas de clasificación complejos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modeloGradientBoostingSup():\n",
    "    def modeloGradientBoosting(df,tamanoMuestra,reemplazo,test,numModelos,criterio,profundidad,minEjemplos,poda,etiqueta,partes,medida,seed):\n",
    "        df = limpiaDataSet(df)\n",
    "        resultadoEnsembler = GradientBoostingClassifier(n_estimators=numModelos,max_depth=profundidad,min_samples_split=minEjemplos,min_impurity_split = poda,random_state=seed)\n",
    "        atributos, clase = separarAtributosClase(df,etiqueta)\n",
    "        metrica = crossValidation(resultadoEnsembler,atributos, clase,partes,medida,seed)\n",
    "        clasificador = resultadoEnsembler.fit(atributos,clase)\n",
    "        resultadoPrediccion = clasificador.predict(test)\n",
    "        return (resultadoEnsembler,resultadoPrediccion,metrica,metrica.mean())\n",
    "    return modeloGradientBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Arbol de Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que se realiza es crear un método aprovechando el orden superior que lo utilizerán los ensembler para la construcción de sus modelos que utilizaran para realizar la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modeloArbolSup():\n",
    "    def modeloArbolS(criterio,profundidad,minEjemplos,poda,seed):\n",
    "        modelo= tree.DecisionTreeClassifier(criterion = criterio, max_depth = profundidad, min_samples_split = minEjemplos, min_impurity_split = poda, random_state = seed)\n",
    "    return modeloArbolS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además se utiliza el mismo método que se implento en la práctica 2 para construir y entrenar un árbol de decisión. Esto es necesario ya que el proceso selección toma como limite maximo de profundidad la que obtiene la que obtiene de un árbol con la configuración por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modeloArbol (df,etiqueta,criterio,profundidad,minEjemplos,poda,partes,medida,seed):\n",
    "    df = limpiaDataSet(df)\n",
    "    modelo= tree.DecisionTreeClassifier(criterion = criterio, max_depth = profundidad, min_samples_split = minEjemplos, min_impurity_split = poda, random_state = seed)\n",
    "    atributos, clase = separarAtributosClase(df,etiqueta)\n",
    "    metrica = crossValidation(modelo,atributos, clase,partes,medida,seed)\n",
    "    return (modelo,metrica,metrica.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selector de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este selector de modelos es una adaptación del modelo de selección de modelos para los árboles de decisión que se implemento en la práctica 2 pero adaptandolo a los ensembler y abstrayendolo en una función.\n",
    "\n",
    "Este método lo que realizar es construir un árbol con una configuración establecida con los valores por defecto para después buscar la profundidad y criterio optimo para el árbol que buscamos. Para realizar esta busqueda lo que realiza es realizar una busqueda por bisección de la profundidad y probar cual de los dos tipos de criterios utilizados es mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimizacionParametros(df,modeloEmseblerOpt,minEjemplos,tamanoMuestra,reemplazo,valoresTest,numModelos,criterio,poda,etiqueta,partes,medida,seed):\n",
    "    profundidad = None\n",
    "    ensemblerArboles={}\n",
    "    modeloMejorEnsemblerArbol=()\n",
    "    atrib_train, clase_train=separarAtributosClase(df,etiqueta)\n",
    "    arbol = modeloArbol(df,etiqueta,criterio[0],profundidad,minEjemplos,poda,partes,medida,seed)\n",
    "    clasificador = arbol[0].fit(atrib_train , clase_train)\n",
    "    min_profundidad = 1\n",
    "    max_profundidad = clasificador.tree_.max_depth\n",
    "    modeloMejorEnsemblerArbol = modeloEmseblerOpt(df,tamanoMuestra,reemplazo,valoresTest,numModelos,criterio[0],max_profundidad,minEjemplos,poda,etiqueta,partes,medida,seed)\n",
    "    ensemblerArboles[(criterio[0],max_profundidad,minEjemplos,poda)]=modeloMejorEnsemblerArbol\n",
    "    profundidad =int((max_profundidad+min_profundidad)/2)\n",
    "    ensemblerArbol=modeloEmseblerOpt(df,tamanoMuestra,reemplazo,valoresTest,numModelos,criterio[0],profundidad,minEjemplos,poda,etiqueta,partes,medida,seed)\n",
    "    ensemblerArboles[(criterio[0],profundidad,minEjemplos,poda)]=ensemblerArbol\n",
    "    while ((modeloMejorEnsemblerArbol[3]<ensemblerArbol[3])and(max_profundidad-min_profundidad>1))and(profundidad>0):\n",
    "        modeloMejorEnsemblerArbol=ensemblerArbol\n",
    "        max_profundidad=profundidad\n",
    "        profundidad =int((max_profundidad+min_profundidad)/2)\n",
    "        for c in criterio:\n",
    "            aux_ensemblerArbol1=modeloEmseblerOpt(df,tamanoMuestra,reemplazo,valoresTest,numModelos,c,profundidad,minEjemplos,poda,etiqueta,partes,medida,seed)\n",
    "            ensemblerArboles[(c,profundidad,minEjemplos,poda)]=aux_ensemblerArbol1\n",
    "            if aux_ensemblerArbol1[3]>=ensemblerArbol[3]:\n",
    "                ensemblerArbol=aux_ensemblerArbol1\n",
    "            if ((modeloMejorEnsemblerArbol[3]>=ensemblerArbol[3])and(max_profundidad-profundidad>=0)):\n",
    "                min_profundidad = profundidad\n",
    "    return [modeloMejorEnsemblerArbol, ensemblerArboles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto, lo que realiza es inicializar la variables necesarias para construir los ensembler basandome en árboles de decisión. Una de la variables es un lista de los módelos que va a tener que generar. Por ultimo, recorre esta lista para generar y obtener los resultados de cada uno de los modelos y mostrarlos de una tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Acurracy</td><td>Ensembler</td></tr><tr><td>0.880419841881</td><td>Propio</td></tr><tr><td>0.813247863248</td><td>RandomForrest</td></tr><tr><td>0.81237143271</td><td>GradientBoosting</td></tr><tr><td>0.794567579313</td><td>Boosting</td></tr><tr><td>0.617992177314</td><td>Bagging</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 3568\n",
    "etiqueta = \"label\"\n",
    "medida = \"accuracy\"\n",
    "partes = 10\n",
    "minEjemplos=2\n",
    "df = titanicdf\n",
    "criterio = (\"entropy\",\"gini\")\n",
    "poda = 1e-7\n",
    "numModelos=100\n",
    "tamanoMuestra=len(df)\n",
    "reemplazo=True\n",
    "valoresTest=df_val\n",
    "resultado={}\n",
    "listaAcurracy=[]\n",
    "modeloEmseblerOpt=((\"Propio\", modeloEnseblerSup()),(\"Bagging\",modeloBaggingSup(modeloArbolSup())),(\"Boosting\",modeloBoostingSup(modeloArbolSup())),(\"RandomForrest\",modeloRandomForrestSup()),(\"GradientBoosting\",modeloGradientBoostingSup()))\n",
    "mejorResultado=None\n",
    "for tipo in modeloEmseblerOpt:\n",
    "    auxResultado=optimizacionParametros(df,tipo[1],minEjemplos,tamanoMuestra,reemplazo,valoresTest,numModelos,criterio,poda,etiqueta,partes,medida,seed)\n",
    "    #print(\"Ensembler \",tipo[0])\n",
    "    #%timeit -n 100 optimizacionParametros(df,tipo[1],minEjemplos,tamanoMuestra,reemplazo,valoresTest,numModelos,criterio,poda,etiqueta,partes,medida,seed)\n",
    "    listaAcurracy.append((auxResultado[0][3],tipo[0]))\n",
    "    resultado[tipo[0]]= auxResultado\n",
    "    if (mejorResultado==None) or (auxResultado[0][3]>mejorResultado[1][0][3]):\n",
    "        mejorResultado=(tipo[0],auxResultado)\n",
    "listaAcurracy=sorted(listaAcurracy,reverse=True)\n",
    "listaAcurracy.insert(0,(\"Acurracy\",\"Ensembler\"))\n",
    "printTable(listaAcurracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que el mejor de los resultados es el del ensembler que he implementado, a pesar de ser algo extraño ya que se esperaba que el Random Forrest fuera el mejor ya que suele obtener muy buenos resultados. He pensado que podría ser un problema con la poda pero después de probar el módelo sin podar se obtiene un resultado peor incluso del modelo obtenido para ese modelo en proceso de optimización. Por lo cual, he de confiar en los resultados que he obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado del Random Forrest sin podar  0.798855570042\n"
     ]
    }
   ],
   "source": [
    "dfRandomForrest = limpiaDataSet(df)\n",
    "resultadoEnsemblerRandomForrest = RandomForestClassifier(n_estimators=numModelos,criterion=\"entropy\",random_state=seed)\n",
    "atributosRandomForrest, claseRandomForrest = separarAtributosClase(dfRandomForrest,etiqueta)\n",
    "metricaRandomForrest = crossValidation(resultadoEnsemblerRandomForrest,atributosRandomForrest, claseRandomForrest,partes,medida,seed)\n",
    "print \"Resultado del Random Forrest sin podar \",metricaRandomForrest.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor modelo es el  Propio  y su valor es  0.880419841881\n"
     ]
    }
   ],
   "source": [
    "print \"El mejor modelo es el \",mejorResultado[0],\" y su valor es \",mejorResultado[1][0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Seleccion de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de ahora, se explicará el proceso de selección de variables que he implementado para los modelos. El estudio se ha realizado en todos los casos con el DataSet de Titanic, el cual se le asigna a la variable dfSeleccion utilizada a partir de ahora en cada uno de los procesos de selección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfSeleccion=df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se explicarán varios procesos de selección de variables para concluir realizando un análisis de los resultados obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas filter y métodos de ranking univariados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consiste en evaluar los atributos del DataSet a partir de medidas estadisticas para obtener la relevación que tienen los atributos en este DataSet.\n",
    "\n",
    "En mi caso he implementado dos métodos distintos. El primero es el proporcionado como ejemplo en la práctica que consiste en obtener la información mútua que tiene cada uno de los atributos del DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Ranking</td><td>Atributo</td></tr><tr><td>0.153785168642</td><td>Sex</td></tr><tr><td>0.128746421116</td><td>Fare</td></tr><tr><td>0.0454132785017</td><td>Pclass</td></tr><tr><td>0.0376224747332</td><td>EmbarkedS</td></tr><tr><td>0.0350278283985</td><td>Parch</td></tr><tr><td>0.0332930029916</td><td>Age</td></tr><tr><td>0.0320793449863</td><td>EmbarkedQ</td></tr><tr><td>0.019016575141</td><td>SibSp</td></tr><tr><td>0.00906885540481</td><td>EmbarkedC</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "seed=1234\n",
    "\n",
    "atributos, clase = separarAtributosClase(dfSeleccion,'label')\n",
    "score = list(mutual_info_classif(atributos, clase, random_state=seed))\n",
    "nombres = list(atributos.columns)\n",
    "ranks = sorted( list(zip(score, nombres)), reverse=True )\n",
    "ranks.insert(0,(\"Ranking\",\"Atributo\"))\n",
    "printTable(ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que los atributos que más información aportan respecto de la clase son el \"Sex\" y \"Fare\" con bastante diferencia con el resto.\n",
    "\n",
    "El segundo método implementado lo que realiza es seleccionar K elementos mas relevantes según el módelo estadistico de independencia Chi². En mi caso no he indicado un valor para K con la opción all. Esto se ha realizado para que me sacará los datos para todos los atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Ranking</td><td>Atributo</td></tr><tr><td>6270.01586244</td><td>Fare</td></tr><tr><td>219.596945869</td><td>Sex</td></tr><tr><td>37.2381562882</td><td>EmbarkedC</td></tr><tr><td>36.494371089</td><td>Pclass</td></tr><tr><td>19.0298430141</td><td>Parch</td></tr><tr><td>14.5577102277</td><td>Age</td></tr><tr><td>10.5738095834</td><td>EmbarkedS</td></tr><tr><td>2.37361435178</td><td>SibSp</td></tr><tr><td>0.220244970245</td><td>EmbarkedQ</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "atributos, clase = separarAtributosClase(dfSeleccion,'label')\n",
    "atributosNuevos = SelectKBest(chi2, k='all')\n",
    "atributosNuevosLista = list(atributosNuevos.fit(atributos, clase).scores_)\n",
    "nombres = list(atributos.columns)\n",
    "ranks = sorted( list(zip(atributosNuevosLista, nombres)), reverse=True )\n",
    "ranks.insert(0,(\"Ranking\",\"Atributo\"))\n",
    "printTable(ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que lo ocurrido en la implementación anterior se puede observar que hay dos atributos que resaltan sobre todos los demas, siendo estos \"Fare\" y \"Sex\". Además se observar que en estas dos implementaciones estos dos atributos son los más relevante a la hora de clasificar este DataSet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos de selección wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método consiste en analizar la relevancia de los atributos para un módelo concreto. En esta técnica existe controversia si se ha de analizar sobre el mismo modelo que se va a aprender, ajustandose de manera especifica corriendo el riesgo de sobreajustar, o relizarlo sobre otro modelo completamente distinto, haciendolo de manera mas general pero corriendo el riesgo de obtener peores resultados.\n",
    "\n",
    "En mi caso, me he decantado por realizar el análisis sobre el clasificar Random Forrest. Esta elección ha sido debida a que este módelo es generico y obtiene como norma general muy buenos resultados, además se puede comparar con la siguiente al estar basadas el mismo algoritmo.\n",
    "\n",
    "Para mi implementación lo que realizo es crear un clasificador Random Forrest, el cual es usado en el modelo RFECV (Eliminación recursiva de atributos con validación cruzada). Para este modelo, la validación cruzada se utiliza realizando dos particiones de manera estratificada. Se ha escogido un valor para la validación cruzada tan pequeño par evitar que el conjunto de selección se puedan dar todos los casos posibles y por motivo no eliminará ningún atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Grupo</td><td>Ranking</td><td>Atributo</td></tr><tr><td>1</td><td>0.665534804754</td><td>Sex</td></tr><tr><td>1</td><td>0.710526315789</td><td>Pclass</td></tr><tr><td>1</td><td>0.748726655348</td><td>Age</td></tr><tr><td>1</td><td>0.782682512733</td><td>Fare</td></tr><tr><td>2</td><td>0.783531409168</td><td>SibSp</td></tr><tr><td>3</td><td>0.782682512733</td><td>Parch</td></tr><tr><td>4</td><td>0.776740237691</td><td>EmbarkedC</td></tr><tr><td>5</td><td>0.779286926995</td><td>EmbarkedS</td></tr><tr><td>6</td><td>0.779286926995</td><td>EmbarkedQ</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "seed=1234\n",
    "\n",
    "atributos, clase = separarAtributosClase(dfSeleccion,'label')\n",
    "\n",
    "randomForest = RandomForestClassifier(n_estimators=50,random_state=seed, criterion=\"entropy\")\n",
    "\n",
    "rfecv = RFECV(estimator=randomForest, step=1, cv=StratifiedKFold(2, random_state=seed), scoring='accuracy')\n",
    "rfecv.fit(atributos, clase)\n",
    "\n",
    "\n",
    "nombres = list(atributos.columns)\n",
    "ranks = sorted( list(zip(rfecv.ranking_, rfecv.grid_scores_, nombres)) )\n",
    "ranks.insert(0,(\"Grupo\",\"Ranking\",\"Atributo\"))\n",
    "printTable(ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que en el primer grupo  nos encontramos con dos atributos que hemos visto anteriormente en los métodos filter que eran muy relevates como son \"Sex\" y \"Fare\". Esto me hace pensar que estos dos atributos son los más relevantes y se apoya en \"Pclass\" y \"Age\" para mejor sus resultados. También se puede observar que \"Fare\" a pesar de ser el atributo que mas información aporta esta relacionado con los otros atributo, ya que al unirlo con los otros la mejora no es muy significativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métrica de Importancia en Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimo, se va analizar la importancia que tiene según el Random Forrest cada uno de los atributos para su su proceso de clasificacción y se va a comparar con los resultados obtenidos en el apartado anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Ranking</td><td>Atributo</td></tr><tr><td>0.29650730303</td><td>Fare</td></tr><tr><td>0.275304992376</td><td>Age</td></tr><tr><td>0.223092456303</td><td>Sex</td></tr><tr><td>0.081539360865</td><td>Pclass</td></tr><tr><td>0.0497897077064</td><td>SibSp</td></tr><tr><td>0.0393302767205</td><td>Parch</td></tr><tr><td>0.0183533052628</td><td>EmbarkedC</td></tr><tr><td>0.0108073421178</td><td>EmbarkedS</td></tr><tr><td>0.00527525561815</td><td>EmbarkedQ</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed=1234\n",
    "\n",
    "atributos, clase = separarAtributosClase(dfSeleccion,'label')\n",
    "\n",
    "# Entrenamos el modelo\n",
    "classifier = randomForest.fit(atributos, clase)\n",
    "\n",
    "# Obtenemos el ranking de características\n",
    "classifier.feature_importances_\n",
    "nombres = list(atributos.columns)\n",
    "ranks = sorted( list(zip(classifier.feature_importances_, nombres)), reverse=True )\n",
    "ranks.insert(0,(\"Ranking\",\"Atributo\"))\n",
    "printTable(ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que los cuatro primeros atributos coinciden con los seleccionados en el apartado anterior. Además, se tiene que el atributo que mas información aporta es \"Fare\" al igual que ocurría en los métodos Filter. En cambio el según lo ha cambiado por \"Age\" segido muy de cerca por \"Sex\", esto es debido a que manera independiente \"Sex\" es mas relevante pero al analizarlo de manera conjunto con \"Fare\" obtiene mas importancia \"Age\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Análisis de Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los resultados obtenidos, de los procesos de selección de variables se puede deducir que los atributos más importes del DataSet son \"Fare\" y \"Sex\". Además, se puede observar que también es muy interesante \"Age\" y en menor medida \"Pclass\" al unirlas con los dos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Acurracy Nuevo</td><td>Acurracy Antiguo</td><td>Ensembler</td></tr><tr><td>0.881458936693</td><td>0.880419841881</td><td>Propio</td></tr><tr><td>0.818361581921</td><td>0.813247863248</td><td>RandomForrest</td></tr><tr><td>0.816644936984</td><td>0.81237143271</td><td>GradientBoosting</td></tr><tr><td>0.800499782703</td><td>0.794567579313</td><td>Boosting</td></tr><tr><td>0.617992177314</td><td>0.617992177314</td><td>Bagging</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 3568\n",
    "etiqueta = \"label\"\n",
    "medida = \"accuracy\"\n",
    "partes = 10\n",
    "minEjemplos=2\n",
    "df = titanicdf\n",
    "df = limpiaDataSet(df)\n",
    "atributosSeleccionados=(\"Fare\", \"Sex\",\"Age\",\"Pclass\")\n",
    "for i in  list(atributos.columns):\n",
    "    if not i in atributosSeleccionados:\n",
    "        df=df.drop(i, 1)\n",
    "criterio = (\"entropy\",\"gini\")\n",
    "poda = 1e-7\n",
    "numModelos=100\n",
    "tamanoMuestra=len(df)\n",
    "reemplazo=True\n",
    "valoresTest=df_val\n",
    "for i in  list(atributos.columns):\n",
    "    if not i in atributosSeleccionados:\n",
    "        valoresTest=valoresTest.drop(i, 1)\n",
    "resultado={}\n",
    "listaAcurracyDict={}\n",
    "for valor in listaAcurracy:\n",
    "    listaAcurracyDict[valor[1]]=valor[0]\n",
    "listaAcurracy2=[]\n",
    "modeloEmseblerOpt=((\"Propio\", modeloEnseblerSup()),(\"Bagging\",modeloBaggingSup(modeloArbolSup())),(\"Boosting\",modeloBoostingSup(modeloArbolSup())),(\"RandomForrest\",modeloRandomForrestSup()),(\"GradientBoosting\",modeloGradientBoostingSup()))\n",
    "mejorResultado=None\n",
    "for tipo in modeloEmseblerOpt:\n",
    "    auxResultado=optimizacionParametros(df,tipo[1],minEjemplos,tamanoMuestra,reemplazo,valoresTest,numModelos,criterio,poda,etiqueta,partes,medida,seed)\n",
    "    #print(\"Ensembler \",tipo[0])\n",
    "    #%timeit -n 100 optimizacionParametros(df,tipo[1],minEjemplos,tamanoMuestra,reemplazo,valoresTest,numModelos,criterio,poda,etiqueta,partes,medida,seed)\n",
    "    listaAcurracy2.append((auxResultado[0][3],listaAcurracyDict[tipo[0]],tipo[0]))\n",
    "    resultado[tipo[0]]= auxResultado\n",
    "    if (mejorResultado==None) or (auxResultado[0][3]>mejorResultado[1][0][3]):\n",
    "        mejorResultado=(tipo[0],auxResultado)\n",
    "listaAcurracy2=sorted(listaAcurracy2,reverse=True)\n",
    "listaAcurracy2.insert(0,(\"Acurracy Nuevo\", \"Acurracy Antiguo\", \"Ensembler\"))\n",
    "printTable(listaAcurracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que al eliminar las variables que no son relevante los resultados obtenidos han mejorar a pesar de que la información que majabamos era menor. Esto demuestra que no toda la información es relevaten a la hora realizar un modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Acurracy Nuevo</td><td>Acurracy Antiguo</td><td>Ensembler</td></tr><tr><td>0.875404527114</td><td>0.880419841881</td><td>Propio</td></tr><tr><td>0.798000869187</td><td>0.81237143271</td><td>GradientBoosting</td></tr><tr><td>0.790388236998</td><td>0.813247863248</td><td>RandomForrest</td></tr><tr><td>0.777625669999</td><td>0.794567579313</td><td>Boosting</td></tr><tr><td>0.617992177314</td><td>0.617992177314</td><td>Bagging</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 3568\n",
    "etiqueta = \"label\"\n",
    "medida = \"accuracy\"\n",
    "partes = 10\n",
    "minEjemplos=2\n",
    "df = titanicdf\n",
    "df = limpiaDataSet(df)\n",
    "atributosSeleccionados=(\"Fare\", \"Sex\",\"Age\")\n",
    "for i in  list(atributos.columns):\n",
    "    if not i in atributosSeleccionados:\n",
    "        df=df.drop(i, 1)\n",
    "criterio = (\"entropy\",\"gini\")\n",
    "poda = 1e-7\n",
    "numModelos=100\n",
    "tamanoMuestra=len(df)\n",
    "reemplazo=True\n",
    "valoresTest=df_val\n",
    "for i in  list(atributos.columns):\n",
    "    if not i in atributosSeleccionados:\n",
    "        valoresTest=valoresTest.drop(i, 1)\n",
    "resultado={}\n",
    "listaAcurracyDict={}\n",
    "for valor in listaAcurracy:\n",
    "    listaAcurracyDict[valor[1]]=valor[0]\n",
    "listaAcurracy3=[]\n",
    "modeloEmseblerOpt=((\"Propio\", modeloEnseblerSup()),(\"Bagging\",modeloBaggingSup(modeloArbolSup())),(\"Boosting\",modeloBoostingSup(modeloArbolSup())),(\"RandomForrest\",modeloRandomForrestSup()),(\"GradientBoosting\",modeloGradientBoostingSup()))\n",
    "mejorResultado=None\n",
    "for tipo in modeloEmseblerOpt:\n",
    "    auxResultado=optimizacionParametros(df,tipo[1],minEjemplos,tamanoMuestra,reemplazo,valoresTest,numModelos,criterio,poda,etiqueta,partes,medida,seed)\n",
    "    #print(\"Ensembler \",tipo[0])\n",
    "    #%timeit -n 100 optimizacionParametros(df,tipo[1],minEjemplos,tamanoMuestra,reemplazo,valoresTest,numModelos,criterio,poda,etiqueta,partes,medida,seed)\n",
    "    listaAcurracy3.append((auxResultado[0][3],listaAcurracyDict[tipo[0]],tipo[0]))\n",
    "    resultado[tipo[0]]= auxResultado\n",
    "    if (mejorResultado==None) or (auxResultado[0][3]>mejorResultado[1][0][3]):\n",
    "        mejorResultado=(tipo[0],auxResultado)\n",
    "listaAcurracy3=sorted(listaAcurracy3,reverse=True)\n",
    "listaAcurracy3.insert(0,(\"Acurracy Nuevo\", \"Acurracy Antiguo\", \"Ensembler\"))\n",
    "printTable(listaAcurracy3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además se puede observar que a \"Pclass\" es la menos relevante de estas cuatro haciendo que si se elimina la variación sea minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
